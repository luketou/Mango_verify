{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# YOLOv3\n",
    "\n",
    "##### 1.  下載安裝 "
   ],
   "metadata": {
    "id": "51bQlVgjmnWf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!git clone https://github.com/zzh8829/yolov3-tf2\r\n",
    "%cd yolov3-tf2/\r\n",
    "!pip install -r requirements-gpu.txt"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cpn-5i4VHbht",
    "outputId": "7b1b96df-f538-4bfc-d1f3-e686cc56a493"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.  確認版本"
   ],
   "metadata": {
    "id": "EIUMAdGXm46J"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%cd yolov3-tf2/\r\n",
    "!ls\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "tf.__version__"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "oyrsdB9THu-8",
    "outputId": "a0b04911-7396-4807-af0d-04975315ac77"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.  預先載入前人訓練好模型權重"
   ],
   "metadata": {
    "id": "wxD-M-g4nZf_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\r\n",
    "!python convert.py"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xymK200gmV25",
    "outputId": "f7c19fab-4f8b-4d5c-eed3-5b70c148065e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4. 初始化模型"
   ],
   "metadata": {
    "id": "ySGg4Ols02rX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\r\n",
    "from absl import app, logging, flags\r\n",
    "from absl.flags import FLAGS\r\n",
    "import time\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from yolov3_tf2.models import (\r\n",
    "    YoloV3, YoloV3Tiny\r\n",
    ")\r\n",
    "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\r\n",
    "from yolov3_tf2.utils import draw_outputs\r\n",
    "\r\n",
    "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\r\n",
    "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\r\n",
    "                    'path to weights file')\r\n",
    "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\r\n",
    "flags.DEFINE_integer('size', 416, 'resize images to')\r\n",
    "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\r\n",
    "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\r\n",
    "flags.DEFINE_string('output', './output.jpg', 'path to output image')\r\n",
    "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\r\n",
    "\r\n",
    "app._run_init(['yolov3'], app.parse_flags_with_usage)\r\n",
    "\r\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "tlgBiU4ZsZY5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4. 偵測影像"
   ],
   "metadata": {
    "id": "laxApAGV07kw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#請輸入影像\r\n",
    "FLAGS.image =\r\n",
    "\r\n",
    "if FLAGS.tiny:\r\n",
    "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\r\n",
    "else:\r\n",
    "    yolo = YoloV3(classes=FLAGS.num_classes)\r\n",
    "      \r\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\r\n",
    "logging.info('weights loaded')\r\n",
    "\r\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\r\n",
    "logging.info('classes loaded')\r\n",
    "\r\n",
    "img_raw = tf.image.decode_image(\r\n",
    "    open(FLAGS.image, 'rb').read(), channels=3)\r\n",
    "\r\n",
    "img = tf.expand_dims(img_raw, 0)\r\n",
    "img = transform_images(img, FLAGS.size)\r\n",
    "\r\n",
    "t1 = time.time()\r\n",
    "boxes, scores, classes, nums = yolo(img)\r\n",
    "t2 = time.time()\r\n",
    "logging.info('time: {}'.format(t2 - t1))\r\n",
    "\r\n",
    "logging.info('detections:')\r\n",
    "for i in range(nums[0]):\r\n",
    "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\r\n",
    "                                        np.array(scores[0][i]),\r\n",
    "                                        np.array(boxes[0][i])))\r\n",
    "\r\n",
    "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\r\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\r\n",
    "\r\n",
    "from IPython.display import Image, display\r\n",
    "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "id": "2iKC1pvBnkDk",
    "outputId": "b15566f3-7c22-433e-c57b-d0e508d794cb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 5. 使用新的資料集訓練新模型"
   ],
   "metadata": {
    "id": "Up4Xcad81FSa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar -O ./data/voc2009_raw.tar\r\n",
    "!mkdir -p ./data/voc2009_raw\r\n",
    "!tar -xf ./data/voc2009_raw.tar -C ./data/voc2009_raw"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用中的字碼頁: 950\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'wget' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用中的字碼頁: 950\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "�R�O�y�k�����T�C\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "使用中的字碼頁: 950"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "tar: Error opening archive: Failed to open './data/voc2009_raw.tar'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-I8Ml-j4Iyuv",
    "outputId": "a1880906-4c01-4f08-a12b-ca2f37582a55"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python tools/voc2012.py \\\r\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\r\n",
    "  --split train \\\r\n",
    "  --output_file ./data/voc_train.tfrecord\r\n",
    "\r\n",
    "!python tools/voc2012.py \\\r\n",
    "  --data_dir './data/voc2009_raw/VOCdevkit/VOC2009' \\\r\n",
    "  --split val \\\r\n",
    "  --output_file ./data/voc_val.tfrecord"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "9lvttM39I5Na",
    "outputId": "faa0df6f-ab49-4476-b2e7-de3c4dbdb5d3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python tools/visualize_dataset.py --dataset ./data/voc_train.tfrecord --classes=./data/voc2012.names"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "GwjLHBgPKblm",
    "outputId": "d76e3cc4-37a2-4615-c29f-6ea133d88bbd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Image\r\n",
    "Image(filename='./output.jpg')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "8OVCJuxQKuMM",
    "outputId": "748e8fb7-4294-4ce9-c436-fafbe1762b25"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python train.py \\\r\n",
    "    --dataset ./data/voc_train.tfrecord \\\r\n",
    "    --val_dataset ./data/voc_val.tfrecord \\\r\n",
    "    --classes ./data/voc2012.names \\\r\n",
    "    --num_classes 20 \\\r\n",
    "    --mode fit --transfer darknet \\\r\n",
    "    --batch_size 16 \\\r\n",
    "    --epochs 3 \\\r\n",
    "    --weights ./checkpoints/yolov3.tf \\\r\n",
    "    --weights_num_classes 80 "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "ZBhryo1I2dwG",
    "outputId": "79963b6f-7f30-4a3d-dd83-792ed28a790d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 6. 使用新的模型進行偵測"
   ],
   "metadata": {
    "id": "zgtlCN1m1TKG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FLAGS.num_classes =\r\n",
    "FLAGS.classes = 'data/voc2012.names'\r\n",
    "FLAGS.weights = 'checkpoints/yolov3_train_3.tf'\r\n",
    "#請輸入影像\r\n",
    "FLAGS.image =\r\n",
    "\r\n",
    "# 訓練不足而降低閾值\r\n",
    "FLAGS.yolo_iou_threshold = 0.2\r\n",
    "FLAGS.yolo_score_threshold = 0.2\r\n",
    "\r\n",
    "if FLAGS.tiny:\r\n",
    "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\r\n",
    "else:\r\n",
    "    yolo = YoloV3(classes=FLAGS.num_classes)\r\n",
    "\r\n",
    "yolo.load_weights(FLAGS.weights).expect_partial()\r\n",
    "logging.info('weights loaded')\r\n",
    "\r\n",
    "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\r\n",
    "logging.info('classes loaded')\r\n",
    "\r\n",
    "img_raw = tf.image.decode_image(\r\n",
    "    open(FLAGS.image, 'rb').read(), channels=3)\r\n",
    "\r\n",
    "img = tf.expand_dims(img_raw, 0)\r\n",
    "img = transform_images(img, FLAGS.size)\r\n",
    "\r\n",
    "t1 = time.time()\r\n",
    "boxes, scores, classes, nums = yolo(img)\r\n",
    "t2 = time.time()\r\n",
    "logging.info('time: {}'.format(t2 - t1))\r\n",
    "\r\n",
    "logging.info('detections:')\r\n",
    "for i in range(nums[0]):\r\n",
    "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\r\n",
    "                                        np.array(scores[0][i]),\r\n",
    "                                        np.array(boxes[0][i])))\r\n",
    "\r\n",
    "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\r\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\r\n",
    "\r\n",
    "from IPython.display import Image, display\r\n",
    "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "wok7x44vNYuP",
    "outputId": "45e152d6-041a-48c9-813d-9d1588d5b4b8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Homework \n",
    "## 請輸入10張同樣的影像給預訓練模型(YOLOv3)及新的資料集訓練新模型後辨認出的差別\n",
    "1. 討論兩個模型辨認效果如何?\n",
    "2. 討論模型為何在辨認上會有錯誤?那些區域造成模型誤判或是沒有辨認出來?\n",
    "** 請於7/23(五) 16:00前繳交作業到google drive自己的資料夾下，請使用word檔繳交"
   ],
   "metadata": {
    "id": "esTFKZzX7jYj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}